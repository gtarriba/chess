---
title: "Chess games analysis"
author: "Gabriel Tarriba"
date: "5/18/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(reticulate)
library(ggplot2)
```

# Analysis of chess results

In this document I analyse a dataset with the results of over 20,000 chess games played on [lichess](https://lichess.org/), one of the most popular platforms to play chess online. The dataset is on [Kaggle](https://www.kaggle.com/datasnaek/chess) and was uploaded by user [Mitchell J](https://www.kaggle.com/datasnaek). All the analysis is performed in [R](https://www.r-project.org/about.html).

I will perform Exploratory Data Analysis as well as some simple Regression Analysis/Machine Learning to find out:

1. What is in the data 
2. How large white's advantage is
3. How rating difference relates to game length (in number of turns)
4. How the rating difference between the two players predicts the outcome of the game 
5. What predicts wether a game will end by checkmate, resignation or time out

```{r}
# Load the dataset and name it df
df <- read.csv("games.csv")
```

## 1. What is in the data

Examine the structure of the dataset, the number of observations and the presence of missing values. We see that there are 16 variables and 20,058 observations. The dataset has no missing values, which is great.

```{r, echo=FALSE, eval = FALSE}

nrow(df)
str(df)
lapply(df, function(x) sum(is.na(x)))

```
## 2. How large is the white advantage

White has the first-mover advantage in chess. But just how significant this really is? How much more does white win compared to black? We see that black wins about 45% of times, and white about 50%. This indicates that a white victory is 4.46 percentage points more likely. However, since black only wins 45% of times, a 4.46 percentage point difference in favor of white means that white is about 9% likelier to win than black!

```{r}
perc_win <- table(df$winner)/nrow(df)*100
print(perc_win)

# Percentage point difference in prob. of white win
perc_win[3] - perc_win[1]

# How much likelier is a white win?
(perc_win[3] - perc_win[1])/perc_win[3]
```

## 3. How do rating difference relates to game length (in number of turns)

Now we use graphs to inspect the distribution of (1) rating differences, (2) the number of turns in a game (i.e. the sum of both players' moves), and (3) how these two are related. But first we need to construct the variable "rating differences", as the absolute value of the ratings. We see that most games are played between rivals of roughly similar strength, which is unsurprising as this is how lichess' algorithm operates by default. The median rating difference is 173 whereas the median game length is 55 turns. Do people with more similar ratings play longer games?

```{r}
# Variable of rating differences
df$diff <- with(df, abs(white_rating - black_rating))
# Summary stats for the two variables of interest
summary(df$diff)
summary(df$turns)
# Histogram of rating differences
hist(df$diff, breaks=50)
# Histogram of game length
hist(df$turns, breaks=50)
# Scatterplot of rating difference and turns
ggplot(df, aes(x=diff, y=turns)) + geom_point(alpha=0.3) # 
```

There seems to be a negative relationship but it's hard to tell because of overplotting. Let's look at games between strong rivals first. We try a different approach: let's look only at games between strong players. For this, we create the var "strength" which is the sum of the ratings of both players. Then we repeat the scatterplot but this time only for games where the sum of the players > 4000 (i.e. where players had an average strength of 2000).

```{r warning=FALSE, message=FALSE}
df$strength <- with(df, white_rating + black_rating)
ggplot(df[df$strength > 4000,], aes(x=diff, y=turns)) + geom_point(alpha=0.2) + geom_smooth(method="lm")
```

Now we see a bit better that games where the rating difference is over 800 points seldom last more than 100 turns, whereas this is very common for games between similarly-rated rivals. But it's still somewhat murky. Another strategy is to turn rating difference into a categorical variable and plot a bar chart. Let's try this approach.

```{r fig.height=5}
# Create categorical variable of rating difference as diffc
df$diff_cat <- cut(df$diff, 
                   breaks=c(-Inf, 400, 800, Inf), 
                   labels=c("Less than 400","400 to 800","Over 800"))

# Group by diffc and estimate mean turns for each category of diffc, then plot 
df %>% 
  group_by(diff_cat) %>% 
  summarize(avg_turn = mean(turns)) %>% 
  ggplot(aes(x=diff+cat, y=avg_turn)) + geom_col(fill="steelblue") + geom_text(aes(label=round(avg_turn, digits=1)), position=position_dodge(width=0.9), vjust=-0.25) + xlab("Absolute rating difference between players") + ylab("Average number of turns")
```

Now we see much more clearly that games between similarly strong rivals are longer than games between unequal rivals.

## 4. How does the rating difference between the two players predicts the outcome of the game?

The rating systems used in lichess is [Glicko 2](https://en.wikipedia.org/wiki/Glicko_rating_system). Just as in the [ELO](https://en.wikipedia.org/wiki/Elo_rating_system) ratings used by International Federation of Chess (FIDE), Glicko 2 ratings indicate the relative strength of players in a given player pool. The rating difference between two players predicts that likelihood that each of them will win. This is the theory. But do we see this in the data?
For this, we're going to 'cut' our rating difference variable into segments, so that we can then estimate the average expected score by category of rating difference. This time we won't use the absolute rating difference but rather the relative rating difference (i.e. allowing it to take both positive and negative values). 

```{r}
df$abs_diff <- with(df, white_rating - black_rating)
hist(df$abs_diff, breaks=50)
df$abs_diffc <- with(df, 
                     cut(abs_diff,
                         breaks = c(-Inf, -500, -400, -300, -200, -100, 0, 100, 200, 300, 400, 500, Inf),
                         right  = FALSE))

```
Now we need to create a numeric result variable that takes the value 1 when white wins, 0 when it's a draw and -1 when black wins.

```{r}
table(df$winner)
df$outcome <- as.numeric(ifelse(df$winner=="white", 1,
                     ifelse(df$winner=="draw", 0,
                            ifelse(df$winner=="black", -1, NA))))
table(df$outcome)
```

And now we can finally plot the expected results versus the rating difference:

```{r}
df %>% 
  group_by(abs_diffc) %>% 
  summarize(mean_score = mean(outcome)) %>% 
  ggplot(aes(x=abs_diffc, y=mean_score)) + geom_col()
```

## 5. What predicts whether a game will end by checkmate, resignation or time out

Now we turn to the most interesting question. In chess, a game can either be a draw or have a decisive result. Games with decisive results can can end (a) with checkmate, (b) with a resignation, or (c) with a time-out (a player runs out of time and loses the game). What affects the type of 'ending' that a game will have? My intuition is that games between stronger players are more likely to end when someone resigns, because stronger players are better at evaluating their chances at winning a losing battle. But let's check it out:

```{r}
df %>% 
  group_by(victory_status) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n)) 
```
We see that more games end with a resignation than with a checkmate. Moreover, less than 1% of games end with a time-out. Now we will train a Machine Learning algorithm to predict when a player will resign versus suffer check mate. For that, we will subset games that end with one of those two outcomes. We split the dataset into a training dataset and a test dataset:

```{r}






```